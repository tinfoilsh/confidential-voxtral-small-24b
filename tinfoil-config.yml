shim-version: v0.3.16@sha256:20220be4487f241e7e2a9af6dd576d20ba35d71307bd777c8dba9ba5da03fb38
cvm-version: 0.6.7
cpus: 16
memory: 65536

models:
  - name: "voxtral-small-24b"
    repo: "mistralai/Voxtral-Small-24B-2507@da5b42409f279fdd92febee0511a6c32828569c1"
    mpk: "1a0c079030ad08e76e547d70a5249df7dd7393b32c945a8c251e15b796121273_97062424576_b75d0e26-035d-5c22-85f8-559f8da80fc9"

containers:
  - name: "voxtral-small-24b"
    image: "ghcr.io/tinfoilsh/vllm-openai-audio:v0.0.10@sha256:67f8af54fba2b39c20f1169ac8ca0ab07065eb31d92ef7a16464433581068163"
    runtime: nvidia
    gpus: all
    ipc: host
    args: [
      "--model", "/tinfoil/mpk/mpk-1a0c079030ad08e76e547d70a5249df7dd7393b32c945a8c251e15b796121273",
      "--served-model-name", "voxtral-small-24b",
      "--tokenizer-mode", "mistral",
      "--config-format", "mistral",
      "--load-format", "mistral",
      "--port", "8001"
    ]

shim:
  listen-port: 443
  upstream-port: 8082
  authenticated: true
  paths:
    - /v1/audio/transcriptions
    - /v1/audio/translations
    - /health
    - /metrics
