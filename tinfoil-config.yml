shim-version: v0.3.5@sha256:f44c65a1f7db476be20c3431bb6facea8c2966606a07fbb5724a619f82bfa558
cvm-version: 0.5.17
cpus: 16
memory: 65536
gpus: full

models:
  - name: "voxtral-small-24b"
    repo: "mistralai/Voxtral-Small-24B-2507@da5b42409f279fdd92febee0511a6c32828569c1"
    mpk: "1a0c079030ad08e76e547d70a5249df7dd7393b32c945a8c251e15b796121273_97062424576_b75d0e26-035d-5c22-85f8-559f8da80fc9"

containers:
  - name: "voxtral-small-24b"
    image: ""
    args: [
      "--runtime", "nvidia",
      "--gpus", "all",
      "--ipc", "host",
      "ghcr.io/tinfoilsh/vllm-openai-audio:v0.0.9@sha256:7d25976ed6b5d3ca81b5a8de15899c4fb41dd07830a4bcee3138901e7be70b6f",
      "--model", "/tinfoil/mpk/mpk-1a0c079030ad08e76e547d70a5249df7dd7393b32c945a8c251e15b796121273",
      "--served-model-name", "voxtral-small-24b",
      "--tokenizer-mode", "mistral",
      "--config-format", "mistral",
      "--load-format", "mistral",
      "--port", "8001"
    ]

shim:
  listen-port: 443
  upstream-port: 8082
  paths:
    - /v1/audio/transcriptions
    - /v1/audio/translations
    - /health
    - /metrics
